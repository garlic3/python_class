

<이전 수업 자료> 

모듈
	하나의 파이썬 파일(.py)

패키지
	파이썬 모듈을 모아 놓은 컨테이너(디렉터리)

라이브러리
	여러 모듈과 패키지를 모아 놓은 컨테이너


웹 크롤링(web crawling)
	완성된 웹 페이지에서 필요한 정보를 수집하여 추출하는 과정
	= 웹 스크래핑

HTML(HyperText Markup Language)
	웹 페이지를 구성하는 언어
	태그종류            내용
	<div class="root">HTML</div>
      시작태그 속성이름 속성값      종료태그

requests 라이브러리
	http 라이브러리

BeautifulSoup4
	구문을 분석해서 필요한 내용만 추출하는 패키지

------------------------------------------------------------------------------------------------
day02 네이버 영화 순위 크롤링
*주피터 노트북 단축키 설명



웹 크롤링(web crawling)
	완성된 웹 페이지에서 필요한 정보를 수집하여 추출하는 과정
	= 웹 스크래핑


HTTP 
웹에서 클라이언트와 서버가 데이터를 주고 받는 규칙(프로토콜)
웹 클라이언트	-> 요청(request)		웹 서버
          	<- 응답(response)  

웹 클라이언트(브라우저)가 웹 서버에 요청을 하면 웹서버는 html로 작성된 문서로 응답하고
이를 웹 브라우저가 해석하여 사용자에게 보여줌
	

HTTP 응답코드
	1xx 진행중 
	2xx 요청 성공
	3xx 요청 완료, 다른페이지 이동
	4xx 사용자의 요청이 잘못됨
	5xx 서버오류


*페이지 소스보기와 검사의 차이
페이지 소스보기: 웹서버에서 보낸 html
개발자 도구: 웹브라우저가 해석한 html

	
HTML(HyperText Markup Language)
	웹 페이지를 구성하는 언어. 요소(Element)로 구성되어 있음

	요소(Element)
		시작태그, 종료태그, 내용을 통틀어 요소(element)라고함

		<태그명 속성이름="속성값">태그내용</태그명>				
		ex) <div class="root">HTML</div>
          	    시작태그                 종료태그

	중첩 요소
		
		<부모 시작태그>
			<자식 시작태그></자식 종료태그>
		</부모 종료태그>


	태그의 속성
		class : 태그들을 그룹화 하는 공통적인 속성
		id : 중복되지 않는 태그의 특정적인 속성
		
requests 라이브러리
	http 라이브러리
	requests.get(url)

	* pip list 설치되어 있는 패키지 목록 보기 
	* https://pypi.org/
** 파이썬에서 url을 통해 요청을 보내고 응답을 받을 수 있게 해주는 라이브러리
		
	
BeautifulSoup4 

	구문을 분석해서 필요한 내용만 추출하는 라이브러리
	https://www.crummy.com/software/BeautifulSoup/bs4/doc/

	find()
		지정된 태그들 중에서 가장 첫번째 태그만 가져오기
		태그: soup.find('태그명')
		태그내용: soup.find('태그명').text
		속성값: soup.find('태그명').get('속성명')

	find_all()
		지정한 태그들을 모두 가져와서 리스트에 보관

		태그: soup.find_all('태그명')
		태그내용: soup.find_all('태그명')[0].text
		속성값: soup.find_all('태그명')[0].get('속성명')


	class 속성 활용 
		
		태그: soup.find_all('태그명', class_='클래스명')
		태그내용: soup.find_all('태그명', class_='클래스명')[0].text
	

	id 속성 활용
		id는 특정값이므로 find_all 사용 x
		태그: soup.find('태그명', id='아이디명')
		태그내용: soup.find('태그명', id='아이디명').text



	CSS 선택자(selector) 활용


	태그명#아이디명 id
	태그명.클래스명 class
	태그명[속성명] 해당 속성을 가진 태그 찾기
	태그명[속성명="속성값"] 해당 속성값을 가진 태그 찾기

	

	select()
		지정한 태그들을 모두 가져와서 리스트에 보관
		태그: soup.select('태그명')
		태그내용: soup.select('태그명')[0].get_text()
		속성값: soup.select('태그명.클래스명')

	select_one()
		지정된 태그들 중에서 가장 첫번째 태그만 가져오기
		태그: soup.select_one('태그명')
		태그내용: soup.select_one('태그명').get_text()
		속성값: soup.select_one('태그명.클래스명')
		       soup.select_one('태그명#아이디명')



	
select(), select_one()	설명
태그이름	태그이름으로 찾음
.클래스이름'	클래스이름으로 찾음
#아이디이름'	아이디이름으로 찾음 (아이디는 연속X)
상위태그이름>자식태그>자식태그'	부모 자식간의 태그 조회' >' 로 구분
상위태그이름 자손태그'	부모 자손간의 태그 조회 #띄어쓰기(공백) 로 구분 #자식을 건너 띈다.
[속성]'	태그 안의 속성을 찾음
태그이름.클래스이름'	해당태그의 클래스이름을 찾음
#아이디이름 > 태그이름.클래스이름
	text.strip()



param = {'key1': 'value1', 'key2':'value2', 'key3':'vaule3'}
response = requests.get(url, params=param)


robots.txt는 검색로봇 또는 검색엔진 크롤러에게 사이트 및 웹페이지를 수집할 수 있도록 허용하거나 제한하는 국제 권고안


https://namu.wiki/w/robots.txt
https://www.google.com/robots.txt

특정 디렉토리의 접근을 허가하려면
User-agent: 제어할 로봇의 User-Agent
Allow: /foo/bar/

특정 디렉토리의 접근을 차단하려면
User-agent: 제어할 로봇의 User-Agent
Disallow: /foo/bar/


모든 문서에 대해 접근을 허가하려면
User-agent: *
Allow: /

모든 문서에 대해 접근을 차단하려면
User-agent: *
Disallow: /

모든 문서에 대해 접근을 차단하고, 첫 페이지에 대해서만 허가
User-agent: *
Disallow: /
Allow : /$
